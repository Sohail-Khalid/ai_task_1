{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index\n",
      "  Downloading llama_index-0.12.19-py3-none-any.whl (7.0 kB)\n",
      "Collecting llama-index-embeddings-openai<0.4.0,>=0.3.0\n",
      "  Downloading llama_index_embeddings_openai-0.3.1-py3-none-any.whl (6.2 kB)\n",
      "Collecting llama-index-core<0.13.0,>=0.12.19\n",
      "  Downloading llama_index_core-0.12.19-py3-none-any.whl (1.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6 MB 245 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting llama-index-multi-modal-llms-openai<0.5.0,>=0.4.0\n",
      "  Downloading llama_index_multi_modal_llms_openai-0.4.3-py3-none-any.whl (5.9 kB)\n",
      "Collecting llama-index-question-gen-openai<0.4.0,>=0.3.0\n",
      "  Downloading llama_index_question_gen_openai-0.3.0-py3-none-any.whl (2.9 kB)\n",
      "Collecting llama-index-readers-file<0.5.0,>=0.4.0\n",
      "  Downloading llama_index_readers_file-0.4.5-py3-none-any.whl (39 kB)\n",
      "Collecting llama-index-agent-openai<0.5.0,>=0.4.0\n",
      "  Downloading llama_index_agent_openai-0.4.6-py3-none-any.whl (13 kB)\n",
      "Collecting llama-index-llms-openai<0.4.0,>=0.3.0\n",
      "  Downloading llama_index_llms_openai-0.3.20-py3-none-any.whl (15 kB)\n",
      "Collecting llama-index-program-openai<0.4.0,>=0.3.0\n",
      "  Downloading llama_index_program_openai-0.3.1-py3-none-any.whl (5.3 kB)\n",
      "Collecting llama-index-indices-managed-llama-cloud>=0.4.0\n",
      "  Downloading llama_index_indices_managed_llama_cloud-0.6.8-py3-none-any.whl (13 kB)\n",
      "Collecting llama-index-readers-llama-parse>=0.4.0\n",
      "  Downloading llama_index_readers_llama_parse-0.4.0-py3-none-any.whl (2.5 kB)\n",
      "Collecting llama-index-cli<0.5.0,>=0.4.0\n",
      "  Downloading llama_index_cli-0.4.0-py3-none-any.whl (27 kB)\n",
      "Collecting nltk>3.8.1\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.5 MB 353 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting openai>=1.14.0\n",
      "  Downloading openai-1.64.0-py3-none-any.whl (472 kB)\n",
      "\u001b[K     |████████████████████████████████| 472 kB 331 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typing-inspect>=0.8.0 in /Users/sohailkhalid/.pyenv/versions/3.10.1/envs/preceptron_3_10_1/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.19->llama-index) (0.9.0)\n",
      "Collecting networkx>=3.0\n",
      "  Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "Collecting filetype<2.0.0,>=1.2.0\n",
      "  Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: requests>=2.31.0 in /Users/sohailkhalid/.pyenv/versions/3.10.1/envs/preceptron_3_10_1/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.19->llama-index) (2.32.3)\n",
      "Collecting deprecated>=1.2.9.3\n",
      "  Downloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
      "Collecting fsspec>=2023.5.0\n",
      "  Using cached fsspec-2025.2.0-py3-none-any.whl (184 kB)\n",
      "Collecting tiktoken>=0.3.3\n",
      "  Downloading tiktoken-0.9.0-cp310-cp310-macosx_10_12_x86_64.whl (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 31.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /Users/sohailkhalid/.pyenv/versions/3.10.1/envs/preceptron_3_10_1/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.19->llama-index) (1.26.4)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /Users/sohailkhalid/.pyenv/versions/3.10.1/envs/preceptron_3_10_1/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.19->llama-index) (9.0.0)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /Users/sohailkhalid/.pyenv/versions/3.10.1/envs/preceptron_3_10_1/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.19->llama-index) (1.6.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/sohailkhalid/.pyenv/versions/3.10.1/envs/preceptron_3_10_1/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.19->llama-index) (4.12.2)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /Users/sohailkhalid/.pyenv/versions/3.10.1/envs/preceptron_3_10_1/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.19->llama-index) (11.1.0)\n",
      "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /Users/sohailkhalid/.pyenv/versions/3.10.1/envs/preceptron_3_10_1/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.19->llama-index) (2.0.38)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /Users/sohailkhalid/.pyenv/versions/3.10.1/envs/preceptron_3_10_1/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.19->llama-index) (3.11.12)\n",
      "Collecting tqdm<5.0.0,>=4.66.1\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "\u001b[K     |████████████████████████████████| 78 kB 15.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: httpx in /Users/sohailkhalid/.pyenv/versions/3.10.1/envs/preceptron_3_10_1/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.19->llama-index) (0.28.1)\n",
      "Requirement already satisfied: dataclasses-json in /Users/sohailkhalid/.pyenv/versions/3.10.1/envs/preceptron_3_10_1/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.19->llama-index) (0.6.7)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /Users/sohailkhalid/.pyenv/versions/3.10.1/envs/preceptron_3_10_1/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.19->llama-index) (6.0.2)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in /Users/sohailkhalid/.pyenv/versions/3.10.1/envs/preceptron_3_10_1/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.19->llama-index) (2.10.6)\n",
      "Collecting dirtyjson<2.0.0,>=1.0.8\n",
      "  Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
      "Collecting wrapt\n",
      "  Downloading wrapt-1.17.2-cp310-cp310-macosx_10_9_x86_64.whl (38 kB)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /Users/sohailkhalid/.pyenv/versions/3.10.1/envs/preceptron_3_10_1/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.19->llama-index) (4.0.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/sohailkhalid/.pyenv/versions/3.10.1/envs/preceptron_3_10_1/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.19->llama-index) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/sohailkhalid/.pyenv/versions/3.10.1/envs/preceptron_3_10_1/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.19->llama-index) (0.2.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/sohailkhalid/.pyenv/versions/3.10.1/envs/preceptron_3_10_1/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.19->llama-index) (1.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/sohailkhalid/.pyenv/versions/3.10.1/envs/preceptron_3_10_1/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.19->llama-index) (1.18.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/sohailkhalid/.pyenv/versions/3.10.1/envs/preceptron_3_10_1/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.19->llama-index) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/sohailkhalid/.pyenv/versions/3.10.1/envs/preceptron_3_10_1/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.19->llama-index) (1.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/sohailkhalid/.pyenv/versions/3.10.1/envs/preceptron_3_10_1/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.19->llama-index) (2.4.6)\n",
      "Collecting llama-cloud<0.2.0,>=0.1.13\n",
      "  Downloading llama_cloud-0.1.13-py3-none-any.whl (253 kB)\n",
      "\u001b[K     |████████████████████████████████| 253 kB 249 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: certifi>=2024.7.4 in /Users/sohailkhalid/.pyenv/versions/3.10.1/envs/preceptron_3_10_1/lib/python3.10/site-packages (from llama-cloud<0.2.0,>=0.1.13->llama-index-indices-managed-llama-cloud>=0.4.0->llama-index) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/sohailkhalid/.pyenv/versions/3.10.1/envs/preceptron_3_10_1/lib/python3.10/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.19->llama-index) (1.0.7)\n",
      "Requirement already satisfied: idna in /Users/sohailkhalid/.pyenv/versions/3.10.1/envs/preceptron_3_10_1/lib/python3.10/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.19->llama-index) (3.10)\n",
      "Requirement already satisfied: anyio in /Users/sohailkhalid/.pyenv/versions/3.10.1/envs/preceptron_3_10_1/lib/python3.10/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.19->llama-index) (4.8.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/sohailkhalid/.pyenv/versions/3.10.1/envs/preceptron_3_10_1/lib/python3.10/site-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.19->llama-index) (0.14.0)\n",
      "Collecting striprtf<0.0.27,>=0.0.26\n",
      "  Downloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
      "Requirement already satisfied: pandas in /Users/sohailkhalid/.pyenv/versions/3.10.1/envs/preceptron_3_10_1/lib/python3.10/site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.2.3)\n",
      "Collecting beautifulsoup4<5.0.0,>=4.12.3\n",
      "  Downloading beautifulsoup4-4.13.3-py3-none-any.whl (186 kB)\n",
      "\u001b[K     |████████████████████████████████| 186 kB 330 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pypdf<6.0.0,>=5.1.0\n",
      "  Downloading pypdf-5.3.0-py3-none-any.whl (300 kB)\n",
      "\u001b[K     |████████████████████████████████| 300 kB 270 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting soupsieve>1.2\n",
      "  Downloading soupsieve-2.6-py3-none-any.whl (36 kB)\n",
      "Collecting llama-parse>=0.5.0\n",
      "  Downloading llama_parse-0.6.1-py3-none-any.whl (4.8 kB)\n",
      "Collecting llama-cloud-services>=0.6.1\n",
      "  Downloading llama_cloud_services-0.6.1-py3-none-any.whl (22 kB)\n",
      "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in /Users/sohailkhalid/.pyenv/versions/3.10.1/envs/preceptron_3_10_1/lib/python3.10/site-packages (from llama-cloud-services>=0.6.1->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (1.0.1)\n",
      "Requirement already satisfied: click<9.0.0,>=8.1.7 in /Users/sohailkhalid/.pyenv/versions/3.10.1/envs/preceptron_3_10_1/lib/python3.10/site-packages (from llama-cloud-services>=0.6.1->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (8.1.8)\n",
      "Collecting regex>=2021.8.3\n",
      "  Downloading regex-2024.11.6-cp310-cp310-macosx_10_9_x86_64.whl (287 kB)\n",
      "\u001b[K     |████████████████████████████████| 287 kB 673 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting joblib\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "\u001b[K     |████████████████████████████████| 301 kB 1.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: sniffio in /Users/sohailkhalid/.pyenv/versions/3.10.1/envs/preceptron_3_10_1/lib/python3.10/site-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.3.1)\n",
      "Collecting distro<2,>=1.7.0\n",
      "  Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Collecting jiter<1,>=0.4.0\n",
      "  Downloading jiter-0.8.2-cp310-cp310-macosx_10_12_x86_64.whl (303 kB)\n",
      "\u001b[K     |████████████████████████████████| 303 kB 320 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: exceptiongroup>=1.0.2 in /Users/sohailkhalid/.pyenv/versions/3.10.1/envs/preceptron_3_10_1/lib/python3.10/site-packages (from anyio->httpx->llama-index-core<0.13.0,>=0.12.19->llama-index) (1.2.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/sohailkhalid/.pyenv/versions/3.10.1/envs/preceptron_3_10_1/lib/python3.10/site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.19->llama-index) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /Users/sohailkhalid/.pyenv/versions/3.10.1/envs/preceptron_3_10_1/lib/python3.10/site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.19->llama-index) (2.27.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/sohailkhalid/.pyenv/versions/3.10.1/envs/preceptron_3_10_1/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.19->llama-index) (2.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/sohailkhalid/.pyenv/versions/3.10.1/envs/preceptron_3_10_1/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.19->llama-index) (3.4.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/sohailkhalid/.pyenv/versions/3.10.1/envs/preceptron_3_10_1/lib/python3.10/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.19->llama-index) (3.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/sohailkhalid/.pyenv/versions/3.10.1/envs/preceptron_3_10_1/lib/python3.10/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.19->llama-index) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/sohailkhalid/.pyenv/versions/3.10.1/envs/preceptron_3_10_1/lib/python3.10/site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.19->llama-index) (3.26.1)\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/sohailkhalid/.pyenv/versions/3.10.1/envs/preceptron_3_10_1/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13.0,>=0.12.19->llama-index) (24.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/sohailkhalid/.pyenv/versions/3.10.1/envs/preceptron_3_10_1/lib/python3.10/site-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/sohailkhalid/.pyenv/versions/3.10.1/envs/preceptron_3_10_1/lib/python3.10/site-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2025.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/sohailkhalid/.pyenv/versions/3.10.1/envs/preceptron_3_10_1/lib/python3.10/site-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/sohailkhalid/.pyenv/versions/3.10.1/envs/preceptron_3_10_1/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (1.17.0)\n",
      "Installing collected packages: wrapt, tqdm, regex, joblib, tiktoken, nltk, networkx, jiter, fsspec, filetype, distro, dirtyjson, deprecated, openai, llama-index-core, llama-index-llms-openai, llama-cloud, soupsieve, llama-index-agent-openai, llama-cloud-services, striprtf, pypdf, llama-parse, llama-index-program-openai, llama-index-embeddings-openai, beautifulsoup4, llama-index-readers-llama-parse, llama-index-readers-file, llama-index-question-gen-openai, llama-index-multi-modal-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-cli, llama-index\n",
      "Successfully installed beautifulsoup4-4.13.3 deprecated-1.2.18 dirtyjson-1.0.8 distro-1.9.0 filetype-1.2.0 fsspec-2025.2.0 jiter-0.8.2 joblib-1.4.2 llama-cloud-0.1.13 llama-cloud-services-0.6.1 llama-index-0.12.19 llama-index-agent-openai-0.4.6 llama-index-cli-0.4.0 llama-index-core-0.12.19 llama-index-embeddings-openai-0.3.1 llama-index-indices-managed-llama-cloud-0.6.8 llama-index-llms-openai-0.3.20 llama-index-multi-modal-llms-openai-0.4.3 llama-index-program-openai-0.3.1 llama-index-question-gen-openai-0.3.0 llama-index-readers-file-0.4.5 llama-index-readers-llama-parse-0.4.0 llama-parse-0.6.1 networkx-3.4.2 nltk-3.9.1 openai-1.64.0 pypdf-5.3.0 regex-2024.11.6 soupsieve-2.6 striprtf-0.0.26 tiktoken-0.9.0 tqdm-4.67.1 wrapt-1.17.2\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the '/Users/sohailkhalid/.pyenv/versions/3.10.1/envs/preceptron_3_10_1/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3.18\n"
     ]
    }
   ],
   "source": [
    "import langchain as lc \n",
    "\n",
    "print(lc.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 1 validation error for HuggingFaceEmbeddings\n",
      "trust_remote_code\n",
      "  Extra inputs are not permitted [type=extra_forbidden, input_value=True, input_type=bool]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/extra_forbidden\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n_/fdsbtmdd5_n6g73pk18fj6bw0000gp/T/ipykernel_42477/1135998018.py:7: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embed_model = HuggingFaceEmbeddings(model_name=\"BAAI/bge-small-en-v1.5\", trust_remote_code=True)\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import Ollama\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "llm = Ollama(model=\"deepseek-r1:1.5b\")\n",
    "\n",
    "try:\n",
    "    embed_model = HuggingFaceEmbeddings(model_name=\"BAAI/bge-small-en-v1.5\", trust_remote_code=True)\n",
    "    print(\"Model loaded successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pypdf in /Users/sohailkhalid/.pyenv/versions/3.10.1/envs/preceptron_3_10_1/lib/python3.10/site-packages (5.3.0)\n",
      "Requirement already satisfied: typing_extensions>=4.0 in /Users/sohailkhalid/.pyenv/versions/3.10.1/envs/preceptron_3_10_1/lib/python3.10/site-packages (from pypdf) (4.12.2)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the '/Users/sohailkhalid/.pyenv/versions/3.10.1/envs/preceptron_3_10_1/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded 1 pages from DSPy.pdf.\n",
      "[Document(metadata={'producer': 'Microsoft® Word 2016', 'creator': 'Microsoft® Word 2016', 'creationdate': '2025-01-31T14:18:56+05:00', 'author': 'Muhammad Rizwan', 'moddate': '2025-01-31T14:18:56+05:00', 'source': 'DSPy.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1'}, page_content=\"DSPy - Programming—not prompting—LMs \\nDSPy is the framework for programming—rather than prompting—language models. It allows \\nyou to iterate fast on building modular AI systems and offers algorithms for optimizing their \\nprompts and weights, whether you're building simple classifiers, sophisticated RAG pipelines, or \\nAgent loops. \\nDSPy stands for Declarative Self-improving Python. Instead of brittle prompts, you write \\ncompositional Python code and use DSPy to teach your LM to deliver high-quality outputs. \\n \\nGetting Started I: Install DSPy and set up your LM \\n> pip install -U dspy \\n \\nLocal LMs on your laptop \\nFirst, install Ollama and launch its server with your LM. \\n> curl -fsSL https://ollama.ai/install.sh | sh \\n> ollama run llama3.2:1b  \\nThen, connect to it from your DSPy code. \\nimport dspy \\nlm = dspy.LM('ollama_chat/llama3.2', api_base='http://localhost:11434', api_key='') \\ndspy.configure(lm=lm)\")]\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "pdf_path = \"DSPy.pdf\"  # Ensure the correct file path\n",
    "\n",
    "try:\n",
    "    loader = PyPDFLoader(pdf_path)\n",
    "    docs = loader.load()\n",
    "    print(f\"✅ Loaded {len(docs)} pages from {pdf_path}.\")\n",
    "    print(docs[:2])  # Print first 2 pages to verify\n",
    "except Exception as e:\n",
    "    print(\"❌ Error loading PDF:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: qdrant-client in /Users/sohailkhalid/.pyenv/versions/3.10.1/envs/preceptron_3_10_1/lib/python3.10/site-packages (1.13.2)\n",
      "Requirement already satisfied: portalocker<3.0.0,>=2.7.0 in /Users/sohailkhalid/.pyenv/versions/3.10.1/envs/preceptron_3_10_1/lib/python3.10/site-packages (from qdrant-client) (2.10.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.26.14 in /Users/sohailkhalid/.pyenv/versions/3.10.1/envs/preceptron_3_10_1/lib/python3.10/site-packages (from qdrant-client) (2.3.0)\n",
      "Requirement already satisfied: httpx[http2]>=0.20.0 in /Users/sohailkhalid/.pyenv/versions/3.10.1/envs/preceptron_3_10_1/lib/python3.10/site-packages (from qdrant-client) (0.28.1)\n",
      "Requirement already satisfied: numpy>=1.21 in /Users/sohailkhalid/.pyenv/versions/3.10.1/envs/preceptron_3_10_1/lib/python3.10/site-packages (from qdrant-client) (1.26.4)\n",
      "Requirement already satisfied: grpcio-tools>=1.41.0 in /Users/sohailkhalid/.pyenv/versions/3.10.1/envs/preceptron_3_10_1/lib/python3.10/site-packages (from qdrant-client) (1.70.0)\n",
      "Requirement already satisfied: pydantic>=1.10.8 in /Users/sohailkhalid/.pyenv/versions/3.10.1/envs/preceptron_3_10_1/lib/python3.10/site-packages (from qdrant-client) (2.10.6)\n",
      "Requirement already satisfied: grpcio>=1.41.0 in /Users/sohailkhalid/.pyenv/versions/3.10.1/envs/preceptron_3_10_1/lib/python3.10/site-packages (from qdrant-client) (1.70.0)\n",
      "Requirement already satisfied: protobuf<6.0dev,>=5.26.1 in /Users/sohailkhalid/.pyenv/versions/3.10.1/envs/preceptron_3_10_1/lib/python3.10/site-packages (from grpcio-tools>=1.41.0->qdrant-client) (5.29.3)\n",
      "Requirement already satisfied: setuptools in /Users/sohailkhalid/.pyenv/versions/3.10.1/envs/preceptron_3_10_1/lib/python3.10/site-packages (from grpcio-tools>=1.41.0->qdrant-client) (58.1.0)\n",
      "Requirement already satisfied: anyio in /Users/sohailkhalid/.pyenv/versions/3.10.1/envs/preceptron_3_10_1/lib/python3.10/site-packages (from httpx[http2]>=0.20.0->qdrant-client) (4.8.0)\n",
      "Requirement already satisfied: idna in /Users/sohailkhalid/.pyenv/versions/3.10.1/envs/preceptron_3_10_1/lib/python3.10/site-packages (from httpx[http2]>=0.20.0->qdrant-client) (3.10)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/sohailkhalid/.pyenv/versions/3.10.1/envs/preceptron_3_10_1/lib/python3.10/site-packages (from httpx[http2]>=0.20.0->qdrant-client) (1.0.7)\n",
      "Requirement already satisfied: certifi in /Users/sohailkhalid/.pyenv/versions/3.10.1/envs/preceptron_3_10_1/lib/python3.10/site-packages (from httpx[http2]>=0.20.0->qdrant-client) (2025.1.31)\n",
      "Requirement already satisfied: h2<5,>=3 in /Users/sohailkhalid/.pyenv/versions/3.10.1/envs/preceptron_3_10_1/lib/python3.10/site-packages (from httpx[http2]>=0.20.0->qdrant-client) (4.2.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/sohailkhalid/.pyenv/versions/3.10.1/envs/preceptron_3_10_1/lib/python3.10/site-packages (from httpcore==1.*->httpx[http2]>=0.20.0->qdrant-client) (0.14.0)\n",
      "Requirement already satisfied: hpack<5,>=4.1 in /Users/sohailkhalid/.pyenv/versions/3.10.1/envs/preceptron_3_10_1/lib/python3.10/site-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client) (4.1.0)\n",
      "Requirement already satisfied: hyperframe<7,>=6.1 in /Users/sohailkhalid/.pyenv/versions/3.10.1/envs/preceptron_3_10_1/lib/python3.10/site-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client) (6.1.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /Users/sohailkhalid/.pyenv/versions/3.10.1/envs/preceptron_3_10_1/lib/python3.10/site-packages (from pydantic>=1.10.8->qdrant-client) (2.27.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/sohailkhalid/.pyenv/versions/3.10.1/envs/preceptron_3_10_1/lib/python3.10/site-packages (from pydantic>=1.10.8->qdrant-client) (0.7.0)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /Users/sohailkhalid/.pyenv/versions/3.10.1/envs/preceptron_3_10_1/lib/python3.10/site-packages (from pydantic>=1.10.8->qdrant-client) (4.12.2)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/sohailkhalid/.pyenv/versions/3.10.1/envs/preceptron_3_10_1/lib/python3.10/site-packages (from anyio->httpx[http2]>=0.20.0->qdrant-client) (1.2.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/sohailkhalid/.pyenv/versions/3.10.1/envs/preceptron_3_10_1/lib/python3.10/site-packages (from anyio->httpx[http2]>=0.20.0->qdrant-client) (1.3.1)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the '/Users/sohailkhalid/.pyenv/versions/3.10.1/envs/preceptron_3_10_1/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install qdrant-client "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n_/fdsbtmdd5_n6g73pk18fj6bw0000gp/T/ipykernel_42477/622345678.py:16: DeprecationWarning: `recreate_collection` method is deprecated and will be removed in the future. Use `collection_exists` to check collection existence and `create_collection` instead.\n",
      "  qdrant_client_local.recreate_collection(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total vectors stored: 1\n",
      "Stored vectors: ([Record(id='d0a7eca0-6eaa-4002-8254-ca68da6890db', payload={'page_content': \"DSPy - Programming—not prompting—LMs \\nDSPy is the framework for programming—rather than prompting—language models. It allows \\nyou to iterate fast on building modular AI systems and offers algorithms for optimizing their \\nprompts and weights, whether you're building simple classifiers, sophisticated RAG pipelines, or \\nAgent loops. \\nDSPy stands for Declarative Self-improving Python. Instead of brittle prompts, you write \\ncompositional Python code and use DSPy to teach your LM to deliver high-quality outputs. \\n \\nGetting Started I: Install DSPy and set up your LM \\n> pip install -U dspy \\n \\nLocal LMs on your laptop \\nFirst, install Ollama and launch its server with your LM. \\n> curl -fsSL https://ollama.ai/install.sh | sh \\n> ollama run llama3.2:1b  \\nThen, connect to it from your DSPy code. \\nimport dspy \\nlm = dspy.LM('ollama_chat/llama3.2', api_base='http://localhost:11434', api_key='') \\ndspy.configure(lm=lm)\", 'metadata': {'producer': 'Microsoft® Word 2016', 'creator': 'Microsoft® Word 2016', 'creationdate': '2025-01-31T14:18:56+05:00', 'author': 'Muhammad Rizwan', 'moddate': '2025-01-31T14:18:56+05:00', 'source': 'DSPy.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1'}}, vector=None, shard_key=None, order_value=None)], None)\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import Qdrant\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import VectorParams, Distance\n",
    "\n",
    "qdrant_client_local = QdrantClient(\"http://localhost:6333\")  \n",
    "collection_name = \"deepseek_langchain\"\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"BAAI/bge-small-en-v1.5\")\n",
    "\n",
    "qdrant_client_local.recreate_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors_config=VectorParams(size=384, distance=Distance.COSINE)  \n",
    ")\n",
    "\n",
    "vector_store = Qdrant.from_documents(\n",
    "    documents=docs,\n",
    "    embedding=embedding_model,\n",
    "    location=\"http://localhost:6333\",\n",
    "    collection_name=collection_name\n",
    ")\n",
    "\n",
    "collection_info = qdrant_client_local.get_collection(collection_name)\n",
    "print(f\"Total vectors stored: {collection_info.points_count}\")\n",
    "\n",
    "stored_vectors = qdrant_client_local.scroll(collection_name=collection_name, limit=3)\n",
    "print(\"Stored vectors:\", stored_vectors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Result 1:\n",
      "DSPy - Programming—not prompting—LMs \n",
      "DSPy is the framework for programming—rather than prompting—language models. It allows \n",
      "you to iterate fast on building modular AI systems and offers algorithms for optimizing their \n",
      "prompts and weights, whether you're building simple classifiers, sophisticated RAG pipelines, or \n",
      "Agent loops. \n",
      "DSPy stands for Declarative Self-improving Python. Instead of brittle prompts, you write \n",
      "compositional Python code and use DSPy to teach your LM to deliver high-quality outputs. \n",
      " \n",
      "Getting Started I: Install DSPy and set up your LM \n",
      "> pip install -U dspy \n",
      " \n",
      "Local LMs on your laptop \n",
      "First, install Ollama and launch its server with your LM. \n",
      "> curl -fsSL https://ollama.ai/install.sh | sh \n",
      "> ollama run llama3.2:1b  \n",
      "Then, connect to it from your DSPy code. \n",
      "import dspy \n",
      "lm = dspy.LM('ollama_chat/llama3.2', api_base='http://localhost:11434', api_key='') \n",
      "dspy.configure(lm=lm)\n"
     ]
    }
   ],
   "source": [
    "query_text = \"what is dspy?\"\n",
    "\n",
    "retrieved_docs = vector_store.similarity_search(query_text, k=3)\n",
    "\n",
    "for idx, doc in enumerate(retrieved_docs):\n",
    "    print(f\"\\n🔹 Result {idx+1}:\")\n",
    "    print(doc.page_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "preceptron_3_10_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
